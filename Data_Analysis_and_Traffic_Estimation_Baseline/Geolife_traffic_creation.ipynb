{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic estimation\n",
    "\n",
    "### Let's start with assigning categorical labels, rather than continuous, because it is simpler\n",
    "\n",
    "**How we can estimate the traffic in the city?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopy.distance import great_circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>alt</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.741415</td>\n",
       "      <td>86.186028</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:00:08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.737063</td>\n",
       "      <td>86.179470</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:01:07</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.734105</td>\n",
       "      <td>86.172823</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:02:07</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.739110</td>\n",
       "      <td>86.166563</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:03:06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.744368</td>\n",
       "      <td>86.159987</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:04:05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044968</th>\n",
       "      <td>40.070186</td>\n",
       "      <td>116.314153</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>2008-11-29 02:01:31</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044969</th>\n",
       "      <td>40.070193</td>\n",
       "      <td>116.314041</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>2008-11-29 02:01:33</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044970</th>\n",
       "      <td>40.070224</td>\n",
       "      <td>116.313923</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>2008-11-29 02:01:35</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044971</th>\n",
       "      <td>40.070227</td>\n",
       "      <td>116.313843</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>2008-11-29 02:01:37</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044972</th>\n",
       "      <td>40.070242</td>\n",
       "      <td>116.313808</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>2008-11-29 02:01:39</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044973 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               lat         lon    alt                time  user_id\n",
       "0        41.741415   86.186028 -777.0 2008-03-31 16:00:08       10\n",
       "1        41.737063   86.179470 -777.0 2008-03-31 16:01:07       10\n",
       "2        41.734105   86.172823 -777.0 2008-03-31 16:02:07       10\n",
       "3        41.739110   86.166563 -777.0 2008-03-31 16:03:06       10\n",
       "4        41.744368   86.159987 -777.0 2008-03-31 16:04:05       10\n",
       "...            ...         ...    ...                 ...      ...\n",
       "2044968  40.070186  116.314153  -45.0 2008-11-29 02:01:31      179\n",
       "2044969  40.070193  116.314041  -48.0 2008-11-29 02:01:33      179\n",
       "2044970  40.070224  116.313923  -51.0 2008-11-29 02:01:35      179\n",
       "2044971  40.070227  116.313843  -56.0 2008-11-29 02:01:37      179\n",
       "2044972  40.070242  116.313808  -58.0 2008-11-29 02:01:39      179\n",
       "\n",
       "[2044973 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('Geolife_all_data.csv')\n",
    "# for some reason after importing the data, the time column is not datetime. So we need to convert it once again\n",
    "all_data['time'] = pd.to_datetime(all_data['time'])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'alt', 'time', 'user_id'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 1:\n",
    "\n",
    "\n",
    "Calculate vehicle speeds from consecutive observations to gauge movement.\n",
    "\n",
    "Aggregate data spatially and temporally to estimate local traffic conditions.\n",
    "\n",
    "Use density and speed metrics to categorize traffic via unsupervised clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start step 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m speeds\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m group\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_speed\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart step 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Step 2: Assign grid cells and time windows\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1567\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     new_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_func\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed on a column. If any error is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraised, this will raise an exception in a future version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof pandas. Drop these columns to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1563\u001b[0m     )\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rewrite_warning(\n\u001b[1;32m   1565\u001b[0m         old_msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, new_msg\n\u001b[1;32m   1566\u001b[0m     ) \u001b[38;5;28;01mif\u001b[39;00m is_np_func \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[0;32m-> 1567\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_selection_context():\n\u001b[1;32m   1578\u001b[0m         \u001b[38;5;66;03m# GH#50538\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1629\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mcompute_speed\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(group) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     13\u001b[0m     loc1 \u001b[38;5;241m=\u001b[39m (group\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], group\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m     loc2 \u001b[38;5;241m=\u001b[39m (\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], group\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m     dt \u001b[38;5;241m=\u001b[39m (group\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m group\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtotal_seconds()\n\u001b[1;32m     16\u001b[0m     speed \u001b[38;5;241m=\u001b[39m great_circle(loc1, loc2)\u001b[38;5;241m.\u001b[39mmeters \u001b[38;5;241m/\u001b[39m dt \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/indexing.py:1627\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/frame.py:3716\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3714\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3716\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3718\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3719\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/internals/managers.py:1126\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(ExtensionDtype, dtype)\n\u001b[1;32m   1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\u001b[38;5;241m.\u001b[39m_from_sequence(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m-> 1126\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[43mnew_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(block, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2180\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   2176\u001b[0m     placement \u001b[38;5;241m=\u001b[39m BlockPlacement(placement)\n\u001b[1;32m   2178\u001b[0m check_ndim(values, placement, ndim)\n\u001b[0;32m-> 2180\u001b[0m klass \u001b[38;5;241m=\u001b[39m \u001b[43mget_block_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(values, ndim\u001b[38;5;241m=\u001b[39mndim, placement\u001b[38;5;241m=\u001b[39mplacement)\n",
      "File \u001b[0;32m~/Desktop/VSCODE/Python/.conda/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2146\u001b[0m, in \u001b[0;36mget_block_type\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m vtype \u001b[38;5;129;01mis\u001b[39;00m Timestamp:\n\u001b[1;32m   2145\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m DatetimeTZBlock\n\u001b[0;32m-> 2146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m(dtype, PeriodDtype):\n\u001b[1;32m   2147\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m NDArrayBackedExtensionBlock\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;66;03m# Note: need to be sure PandasArray is unwrapped before we get here\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = all_data.copy()\n",
    "print('Start step 1')\n",
    "# Step 1: Calculate speeds\n",
    "# This function computes the speed between consecutive observations for each user, but it needs verification (that it works correctly)\n",
    "def compute_speed(group):\n",
    "    group = group.sort_values('time')\n",
    "    speeds = []\n",
    "    for i in range(len(group) - 1):\n",
    "        loc1 = (group.iloc[i]['lat'], group.iloc[i]['lon'])\n",
    "        loc2 = (group.iloc[i+1]['lat'], group.iloc[i+1]['lon'])\n",
    "        dt = (group.iloc[i+1]['time'] - group.iloc[i]['time']).total_seconds()\n",
    "        speed = great_circle(loc1, loc2).meters / dt if dt > 0 else 0\n",
    "        speeds.append(speed)\n",
    "    speeds.append(np.nan)\n",
    "    group['speed'] = speeds\n",
    "    return group\n",
    "\n",
    "df = df.groupby('user_id').apply(compute_speed).reset_index(drop=True)\n",
    "\n",
    "print('Start step 2')\n",
    "# Step 2: Assign grid cells and time windows\n",
    "def get_grid_cell(lat, lon, size=100):\n",
    "    # Simple grid mapping (adjust for precision)\n",
    "    \"\"\"\n",
    "    The function is designed to map a given latitude and longitude to a specific grid cell based on a predefined size. This function is useful in applications where spatial data needs to be organized into a grid for easier analysis or visualization.\n",
    "    \"\"\"\n",
    "    return (int(lat * 10000 / size), int(lon * 10000 / size))\n",
    "\n",
    "df['grid_cell'] = df.apply(lambda row: get_grid_cell(row['lat'], row['lon']), axis=1)\n",
    "df['time_window'] = df['time'].dt.floor('5min')\n",
    "\n",
    "print('Start step 3')\n",
    "# Step 3: Aggregate\n",
    "agg_data = []\n",
    "for (cell, tw), group in df.groupby(['grid_cell', 'time_window']):\n",
    "    N = group['user_id'].nunique()\n",
    "    if N > 0:\n",
    "        S = group.groupby('user_id')['speed'].mean().mean()  # Average of user averages\n",
    "        agg_data.append({'grid_cell': cell, 'time_window': tw, 'N': N, 'S': S})\n",
    "\n",
    "agg_df = pd.DataFrame(agg_data)\n",
    "\n",
    "print('Start step 4')\n",
    "# Step 4: Cluster\n",
    "features = agg_df[['N', 'S']].dropna()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(features_scaled)\n",
    "agg_df['traffic'] = pd.Series(labels, index=features.index)\n",
    "\n",
    "# Assign labels (adjust based on actual centers)\n",
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "traffic_map = {0: 'low', 1: 'medium', 2: 'high'}  # Example; validate with centers\n",
    "agg_df['traffic'] = agg_df['traffic'].map(traffic_map)\n",
    "\n",
    "# Step 5: Map back to observations\n",
    "df = df.merge(agg_df[['grid_cell', 'time_window', 'traffic']], \n",
    "              on=['grid_cell', 'time_window'], how='left')\n",
    "df['traffic'] = df['traffic'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes too long for execution for now, let's make it on a subset. For each user we will take the first 500 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>alt</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.741415</td>\n",
       "      <td>86.186028</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:00:08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.737063</td>\n",
       "      <td>86.179470</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:01:07</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.734105</td>\n",
       "      <td>86.172823</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:02:07</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.739110</td>\n",
       "      <td>86.166563</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:03:06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.744368</td>\n",
       "      <td>86.159987</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>2008-03-31 16:04:05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23348</th>\n",
       "      <td>40.087501</td>\n",
       "      <td>116.313351</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2008-08-21 09:03:44</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23349</th>\n",
       "      <td>40.087483</td>\n",
       "      <td>116.313329</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2008-08-21 09:03:46</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23350</th>\n",
       "      <td>40.087469</td>\n",
       "      <td>116.313308</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2008-08-21 09:03:48</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23351</th>\n",
       "      <td>40.087469</td>\n",
       "      <td>116.313278</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2008-08-21 09:03:50</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>40.087475</td>\n",
       "      <td>116.313238</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2008-08-21 09:03:52</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23353 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lat         lon    alt                time  user_id\n",
       "0      41.741415   86.186028 -777.0 2008-03-31 16:00:08       10\n",
       "1      41.737063   86.179470 -777.0 2008-03-31 16:01:07       10\n",
       "2      41.734105   86.172823 -777.0 2008-03-31 16:02:07       10\n",
       "3      41.739110   86.166563 -777.0 2008-03-31 16:03:06       10\n",
       "4      41.744368   86.159987 -777.0 2008-03-31 16:04:05       10\n",
       "...          ...         ...    ...                 ...      ...\n",
       "23348  40.087501  116.313351  192.0 2008-08-21 09:03:44      179\n",
       "23349  40.087483  116.313329  195.0 2008-08-21 09:03:46      179\n",
       "23350  40.087469  116.313308  195.0 2008-08-21 09:03:48      179\n",
       "23351  40.087469  116.313278  193.0 2008-08-21 09:03:50      179\n",
       "23352  40.087475  116.313238  190.0 2008-08-21 09:03:52      179\n",
       "\n",
       "[23353 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the first 500 observations for each user_id\n",
    "filtered_data = all_data.groupby('user_id').head(500).reset_index(drop=True)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start step 1\n",
      "Start step 2\n",
      "Start step 3\n",
      "Start step 4\n"
     ]
    }
   ],
   "source": [
    "df = filtered_data.copy()\n",
    "print('Start step 1')\n",
    "# Step 1: Calculate speeds\n",
    "# This function computes the speed between consecutive observations for each user, but it needs verification (that it works correctly)\n",
    "def compute_speed(group):\n",
    "    group = group.sort_values('time')\n",
    "    speeds = []\n",
    "    for i in range(len(group) - 1):\n",
    "        loc1 = (group.iloc[i]['lat'], group.iloc[i]['lon'])\n",
    "        loc2 = (group.iloc[i+1]['lat'], group.iloc[i+1]['lon'])\n",
    "        dt = (group.iloc[i+1]['time'] - group.iloc[i]['time']).total_seconds()\n",
    "        speed = great_circle(loc1, loc2).meters / dt if dt > 0 else 0\n",
    "        speeds.append(speed)\n",
    "    speeds.append(np.nan)\n",
    "    group['speed'] = speeds\n",
    "    return group\n",
    "\n",
    "df = df.groupby('user_id').apply(compute_speed).reset_index(drop=True)\n",
    "\n",
    "print('Start step 2')\n",
    "# Step 2: Assign grid cells and time windows\n",
    "def get_grid_cell(lat, lon, size=100):\n",
    "    # Simple grid mapping (adjust for precision)\n",
    "    \"\"\"\n",
    "    The function is designed to map a given latitude and longitude to a specific grid cell based on a predefined size. This function is useful in applications where spatial data needs to be organized into a grid for easier analysis or visualization.\n",
    "    \"\"\"\n",
    "    return (int(lat * 10000 / size), int(lon * 10000 / size))\n",
    "\n",
    "df['grid_cell'] = df.apply(lambda row: get_grid_cell(row['lat'], row['lon']), axis=1)\n",
    "df['time_window'] = df['time'].dt.floor('5min')\n",
    "\n",
    "print('Start step 3')\n",
    "# Step 3: Aggregate\n",
    "agg_data = []\n",
    "for (cell, tw), group in df.groupby(['grid_cell', 'time_window']):\n",
    "    N = group['user_id'].nunique()\n",
    "    if N > 0:\n",
    "        S = group.groupby('user_id')['speed'].mean().mean()  # Average of user averages\n",
    "        agg_data.append({'grid_cell': cell, 'time_window': tw, 'N': N, 'S': S})\n",
    "\n",
    "agg_df = pd.DataFrame(agg_data)\n",
    "\n",
    "print('Start step 4')\n",
    "# Step 4: Cluster\n",
    "features = agg_df[['N', 'S']].dropna()\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(features_scaled)\n",
    "agg_df['traffic'] = pd.Series(labels, index=features.index)\n",
    "\n",
    "# Assign labels (adjust based on actual centers)\n",
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "traffic_map = {0: 'low', 1: 'medium', 2: 'high'}  # Example; validate with centers\n",
    "agg_df['traffic'] = agg_df['traffic'].map(traffic_map)\n",
    "\n",
    "# Step 5: Map back to observations\n",
    "df = df.merge(agg_df[['grid_cell', 'time_window', 'traffic']], \n",
    "              on=['grid_cell', 'time_window'], how='left')\n",
    "df['traffic'] = df['traffic'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium     20246\n",
       "low         3093\n",
       "unknown       10\n",
       "high           4\n",
       "Name: traffic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.traffic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Well, at least it is not medium all the time, hence, the approach is not as naive (especially for the first attempt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make continuous predictions and improve the pipeline?\n",
    "\n",
    "In general, traffic load is influenced by:\n",
    "\n",
    "Density: The number of unique vehicles (or users) in a specific area (e.g., a grid cell) over a given time window. Higher density suggests more crowded conditions.\n",
    "\n",
    "Speed: The average speed of vehicles in that area and time window. Lower speeds often indicate congestion, while higher speeds suggest smoother flow.\n",
    "\n",
    "The goal is to combine these indicators into a single continuous metric that increases with density and decreases with speed, reflecting real-world traffic dynamics.\n",
    "\n",
    "However, since our data is probably not sufficient (at least for now) to estimate density, we need to think about the function which takes speed as an input, and produces a continuous value of traffic as an output (or find more data for better representation). Another thing to consider is data aggregation. Currenty we mapped every input to an output, however, a more realistic approach would be to map a group of inputs to an output, since we do not need to estimate the traffic every two seconds, and also it requires a lot of computations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
